{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ae2b19-e3de-4338-8f1a-9ae76023340f",
   "metadata": {},
   "source": [
    "# Part 5 -- Model v3 Evaluation -- Base LLM model on the \"Industry\", \"Meta-description\" and \"Homepage text\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0611d4c4-9b55-49ac-9811-79a204d698d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bishop/miniconda3/envs/dialectica/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EarlyStoppingCallback, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf26084-76ad-41cf-8e93-11b839904744",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6187c-0e37-491a-ba3e-b4b34de2071b",
   "metadata": {},
   "source": [
    "## Load exported Full and Train datasets to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b7dd2a-7f4a-4cb6-9647-142749a6d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'dataset.csv'))\n",
    "df_train = pd.read_csv(os.path.join('data', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2939699-85d8-4171-89d5-a57658cda86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ft2'\n",
    "text_cols = ['industry', 'meta_description', 'homepage_text']\n",
    "label_col = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b62d985-ac6d-42ae-8025-379797b5faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id']+text_cols+[label_col]]\n",
    "df_train = df_train[['id']+text_cols+[label_col]].dropna(subset=text_cols).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d02e3e-3454-4b31-bae7-854da1c555c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = df[label_col].dropna().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aba811-7fa5-42a0-8306-93c0e949d50a",
   "metadata": {},
   "source": [
    "## Extract Evaluation data as the set of samples which were not used in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19eeb611-e6e3-4427-a863-4266b89f27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df.loc[~df['id'].isin(df_train['id'].tolist()), ['id']+text_cols+[label_col]].dropna(subset=text_cols+[label_col]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d7992-73f8-4dbc-a47a-a39fdbbf2283",
   "metadata": {},
   "source": [
    "## Load stored label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec6b209-5084-43be-83e5-9275c5d0a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = None\n",
    "le_inv = None\n",
    "\n",
    "with open(os.path.join('data', 'labels.json'), 'r') as j:\n",
    "    json_contents = json.loads(j.read())\n",
    "\n",
    "    le = {k: int(v) for k, v in json_contents.items()}\n",
    "    le_inv = {int(v): k for k, v in json_contents.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e1b5c-484c-459b-99bf-5d572ce3dea6",
   "metadata": {},
   "source": [
    "## Data transformation based on Label (category) and Text (input) feature(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18b5717-da96-4a2a-b943-4f7e24309a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing HTML tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # Remove redundant whitespaces at the beginning and at the end\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "for col in text_cols:\n",
    "    texts = []\n",
    "    for sen in list(df_train[col].astype(str)):\n",
    "        texts.append(preprocess_text(sen))\n",
    "    df_train.loc[:, col] = pd.Series((sen for sen in texts))\n",
    "\n",
    "for col in text_cols:\n",
    "    texts = []\n",
    "    for sen in list(df_eval[col].astype(str)):\n",
    "        texts.append(preprocess_text(sen))\n",
    "    df_eval.loc[:, col] = pd.Series((sen for sen in texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8805e2-5680-49aa-a489-cd379ea677de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train[text_cols].apply(lambda x: ' [SEP] '.join(x.values.astype(str)), axis=1)\n",
    "df_eval['text'] = df_eval[text_cols].apply(lambda x: ' [SEP] '.join(x.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dab09b5-e862-4b34-be73-cef51c7cbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=['text']).reset_index(drop=True)\n",
    "df_eval = df_eval.dropna(subset=['text']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20399956-3348-41a6-9103-8c4685c4f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:, 'label'] = df_train[label_col].apply(lambda x: le[x])\n",
    "df_eval.loc[:, 'label'] = df_eval[label_col].apply(lambda x: le[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27993312-24e2-46da-b2eb-72960ebfb9a9",
   "metadata": {},
   "source": [
    "## Tokenize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dab1d86-1803-4fa9-b18a-dfb8c4158309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4056a6a6-052f-4f6b-a108-75420f80586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_pandas(df_train[['label', 'text']])\n",
    "ds_eval = Dataset.from_pandas(df_eval[['label', 'text']])\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': ds_train,\n",
    "    'eval': ds_eval,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aede76bc-8904-4889-a3ea-197d1140e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████| 26308/26308 [01:00<00:00, 437.49 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████| 39815/39815 [01:25<00:00, 463.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "ds_tokenized = ds.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1871eff2-4f08-470d-aba8-f1a53835d281",
   "metadata": {},
   "source": [
    "## Configure model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b49243-1fcc-4686-b3d5-7d27eb7fa70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = AutoConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "configuration.hidden_dropout_prob = 0.2\n",
    "configuration.attention_probs_dropout_prob = 0.2\n",
    "\n",
    "# Load fine-tuned Bert model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f'output/{model_name}', config=configuration)\n",
    "\n",
    "# Move Bert model to the proper device\n",
    "model.to(device)\n",
    "\n",
    "# Switch Bert model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd568cf-db8b-4747-a8c7-b93e1069ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    push_to_hub=False,\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=13,\n",
    "    per_device_eval_batch_size=13*int(6*len(df_eval)/len(df_train)),\n",
    "\n",
    "    save_strategy='steps',\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    logging_steps=200,\n",
    "    \n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fe54b34-c1f7-4e0d-bfd3-9ff07c093f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load('accuracy')\n",
    "precision_metric = evaluate.load('precision')\n",
    "recall_metric = evaluate.load('recall')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy_metric.compute(predictions=predictions, references=labels)['accuracy'],\n",
    "        'F1': f1_metric.compute(predictions=predictions, references=labels, average='weighted')['f1'],\n",
    "        'Precision': precision_metric.compute(predictions=predictions, references=labels, average='weighted')['precision'],\n",
    "        'Recall': recall_metric.compute(predictions=predictions, references=labels, average='weighted')['recall'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9826ff-a9b6-4a1f-b307-1170c835148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStoppingCallback(5, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0464ce9c-cc36-4c24-844f-4466486490ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_tokenized['train'],\n",
    "    eval_dataset=ds_tokenized['eval'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d6fd7-a833-49b5-b1b2-d2cdf32581d6",
   "metadata": {},
   "source": [
    "## Model evaluation on labeled samples which are not part of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49f57167-2cee-46ad-a772-813e35a2b22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='341' max='341' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [341/341 16:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.001234974479302764,\n",
       " 'eval_model_preparation_time': 0.0021,\n",
       " 'eval_Accuracy': 0.9997990707019967,\n",
       " 'eval_F1': 0.9997991047411801,\n",
       " 'eval_Precision': 0.9997992348263167,\n",
       " 'eval_Recall': 0.9997990707019967,\n",
       " 'eval_runtime': 1020.4704,\n",
       " 'eval_samples_per_second': 39.016,\n",
       " 'eval_steps_per_second': 0.334}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda59e1-85b8-4102-85c0-9f7c92667929",
   "metadata": {},
   "source": [
    "## Manual category prediction of 10 random unlabeled samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a687efc-c0e0-4e3f-9db6-38e620589696",
   "metadata": {},
   "source": [
    "### Extract Test data as the set of unlabeled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a79ca8-f213-472d-b268-050fe9007c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[df[label_col].isna(), ['id']+text_cols].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530cff5-a164-464d-865f-aef79040463a",
   "metadata": {},
   "source": [
    "### Data transformation based on Label (category) and Text (input) feature(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43e704f8-7cb5-4415-9779-0381f0ac9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    texts = []\n",
    "    for sen in list(df_test[col].astype(str)):\n",
    "        texts.append(preprocess_text(sen))\n",
    "    df_test.loc[:, col] = pd.Series((sen for sen in texts))\n",
    "\n",
    "df_test['text'] = df_test[text_cols].apply(lambda x: ' [SEP] '.join(x.values.astype(str)), axis=1)\n",
    "df_test = df_test.dropna(subset=['text']).reset_index(drop=True)\n",
    "df_test['label'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48df358-69c2-4f4e-b5f7-5b966c51c7dc",
   "metadata": {},
   "source": [
    "### Perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf287a3-53ca-485d-bcd9-108c81b174a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m      2\u001b[0m     sample \u001b[38;5;241m=\u001b[39m df_test\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Tokenize text features\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dialectica/lib/python3.10/site-packages/pandas/core/generic.py:6118\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6116\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6118\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/miniconda3/envs/dialectica/lib/python3.10/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:968\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "for i in df_test.sample(n=10).index:\n",
    "    sample = df_test.iloc[i]\n",
    "\n",
    "    # Tokenize text features\n",
    "    tokenized = tokenizer(sample['text'], padding='max_length', truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict label\n",
    "        outputs=model(**tokenized)\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "        # Store prediction\n",
    "        df_test.loc[i, 'pred'] = le_inv[torch.argmax(probabilities, dim=-1).item()]\n",
    "\n",
    "    print(df_test.loc[i, text_cols+['pred']])\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
