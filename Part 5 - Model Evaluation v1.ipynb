{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321788bb-7b39-43df-93ae-534d463340ab",
   "metadata": {},
   "source": [
    "# Part 5 -- Model v1 Evaluation -- Base LLM model on the \"Industry\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0611d4c4-9b55-49ac-9811-79a204d698d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bishop/miniconda3/envs/dialectica/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EarlyStoppingCallback, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf26084-76ad-41cf-8e93-11b839904744",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6187c-0e37-491a-ba3e-b4b34de2071b",
   "metadata": {},
   "source": [
    "## Load exported Full and Train datasets to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b7dd2a-7f4a-4cb6-9647-142749a6d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'dataset.csv'))\n",
    "df_train = pd.read_csv(os.path.join('data', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2939699-85d8-4171-89d5-a57658cda86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ft1'\n",
    "text_cols = ['industry']\n",
    "label_col = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b62d985-ac6d-42ae-8025-379797b5faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id']+text_cols+[label_col]]\n",
    "df_train = df_train[['id']+text_cols+[label_col]].dropna(subset=text_cols).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d02e3e-3454-4b31-bae7-854da1c555c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = df[label_col].dropna().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aba811-7fa5-42a0-8306-93c0e949d50a",
   "metadata": {},
   "source": [
    "## Extract Evaluation data as the set of samples which were not used in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19eeb611-e6e3-4427-a863-4266b89f27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df.loc[~df['id'].isin(df_train['id'].tolist()), ['id']+text_cols+[label_col]].dropna(subset=[label_col]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d7992-73f8-4dbc-a47a-a39fdbbf2283",
   "metadata": {},
   "source": [
    "## Load stored label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec6b209-5084-43be-83e5-9275c5d0a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = None\n",
    "le_inv = None\n",
    "\n",
    "with open(os.path.join('data', 'labels.json'), 'r') as j:\n",
    "    json_contents = json.loads(j.read())\n",
    "\n",
    "    le = {k: int(v) for k, v in json_contents.items()}\n",
    "    le_inv = {int(v): k for k, v in json_contents.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e1b5c-484c-459b-99bf-5d572ce3dea6",
   "metadata": {},
   "source": [
    "## Data transformation based on Label (category) and Text (input) feature(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18b5717-da96-4a2a-b943-4f7e24309a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing HTML tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # Remove redundant whitespaces at the beginning and at the end\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "for col in text_cols:\n",
    "    texts = []\n",
    "    for sen in list(df_train[col].astype(str)):\n",
    "        texts.append(preprocess_text(sen))\n",
    "    df_train.loc[:, col] = pd.Series((sen for sen in texts))\n",
    "\n",
    "for col in text_cols:\n",
    "    texts = []\n",
    "    for sen in list(df_eval[col].astype(str)):\n",
    "        texts.append(preprocess_text(sen))\n",
    "    df_eval.loc[:, col] = pd.Series((sen for sen in texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8805e2-5680-49aa-a489-cd379ea677de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train[text_cols].apply(lambda x: ' [SEP] '.join(x.values.astype(str)), axis=1)\n",
    "df_eval['text'] = df_eval[text_cols].apply(lambda x: ' [SEP] '.join(x.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dab09b5-e862-4b34-be73-cef51c7cbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=['text']).reset_index(drop=True)\n",
    "df_eval = df_eval.dropna(subset=['text']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20399956-3348-41a6-9103-8c4685c4f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:, 'label'] = df_train[label_col].apply(lambda x: le[x])\n",
    "df_eval.loc[:, 'label'] = df_eval[label_col].apply(lambda x: le[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27993312-24e2-46da-b2eb-72960ebfb9a9",
   "metadata": {},
   "source": [
    "## Tokenize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dab1d86-1803-4fa9-b18a-dfb8c4158309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4056a6a6-052f-4f6b-a108-75420f80586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_pandas(df_train[['label', 'text']])\n",
    "ds_eval = Dataset.from_pandas(df_eval[['label', 'text']])\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': ds_train,\n",
    "    'eval': ds_eval,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aede76bc-8904-4889-a3ea-197d1140e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████| 26494/26494 [00:06<00:00, 3911.58 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████| 46954/46954 [00:12<00:00, 3844.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "ds_tokenized = ds.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1871eff2-4f08-470d-aba8-f1a53835d281",
   "metadata": {},
   "source": [
    "## Configure model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b49243-1fcc-4686-b3d5-7d27eb7fa70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = AutoConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "configuration.hidden_dropout_prob = 0.2\n",
    "configuration.attention_probs_dropout_prob = 0.2\n",
    "\n",
    "# Load fine-tuned Bert model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f'output/{model_name}', config=configuration)\n",
    "\n",
    "# Move Bert model to the proper device\n",
    "model.to(device)\n",
    "\n",
    "# Switch Bert model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd568cf-db8b-4747-a8c7-b93e1069ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    push_to_hub=False,\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=13,\n",
    "    per_device_eval_batch_size=13*int(5*len(df_eval)/len(df_train)),\n",
    "\n",
    "    save_strategy='steps',\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    logging_steps=200,\n",
    "    \n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fe54b34-c1f7-4e0d-bfd3-9ff07c093f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load('accuracy')\n",
    "precision_metric = evaluate.load('precision')\n",
    "recall_metric = evaluate.load('recall')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy_metric.compute(predictions=predictions, references=labels)['accuracy'],\n",
    "        'F1': f1_metric.compute(predictions=predictions, references=labels, average='weighted')['f1'],\n",
    "        'Precision': precision_metric.compute(predictions=predictions, references=labels, average='weighted')['precision'],\n",
    "        'Recall': recall_metric.compute(predictions=predictions, references=labels, average='weighted')['recall'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9826ff-a9b6-4a1f-b307-1170c835148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStoppingCallback(5, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0464ce9c-cc36-4c24-844f-4466486490ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_tokenized['train'],\n",
    "    eval_dataset=ds_tokenized['eval'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d6fd7-a833-49b5-b1b2-d2cdf32581d6",
   "metadata": {},
   "source": [
    "## Model evaluation on labeled samples which are not part of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49f57167-2cee-46ad-a772-813e35a2b22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='452' max='452' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [452/452 19:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0004986003623344004,\n",
       " 'eval_model_preparation_time': 0.0023,\n",
       " 'eval_Accuracy': 0.9999361076798569,\n",
       " 'eval_F1': 0.9999361072531957,\n",
       " 'eval_Precision': 0.999936152611165,\n",
       " 'eval_Recall': 0.9999361076798569,\n",
       " 'eval_runtime': 1185.0644,\n",
       " 'eval_samples_per_second': 39.621,\n",
       " 'eval_steps_per_second': 0.381}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda59e1-85b8-4102-85c0-9f7c92667929",
   "metadata": {},
   "source": [
    "## Manual category prediction of 10 random unlabeled samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a687efc-c0e0-4e3f-9db6-38e620589696",
   "metadata": {},
   "source": [
    "### Extract Test data as the set of unlabeled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a79ca8-f213-472d-b268-050fe9007c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[df[label_col].isna(), ['id']+text_cols].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530cff5-a164-464d-865f-aef79040463a",
   "metadata": {},
   "source": [
    "### Data transformation based on Label (category) and Text (input) feature(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43e704f8-7cb5-4415-9779-0381f0ac9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    texts = []\n",
    "    for sen in list(df_test[col].astype(str)):\n",
    "        texts.append(preprocess_text(sen))\n",
    "    df_test.loc[:, col] = pd.Series((sen for sen in texts))\n",
    "\n",
    "df_test['text'] = df_test[text_cols].apply(lambda x: ' [SEP] '.join(x.values.astype(str)), axis=1)\n",
    "df_test = df_test.dropna(subset=['text']).reset_index(drop=True)\n",
    "df_test['label'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48df358-69c2-4f4e-b5f7-5b966c51c7dc",
   "metadata": {},
   "source": [
    "### Perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf287a3-53ca-485d-bcd9-108c81b174a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry           legal services\n",
      "pred        Professional Services\n",
      "Name: 782405, dtype: object\n",
      "\n",
      "\n",
      "industry          human resources\n",
      "pred        Professional Services\n",
      "Name: 3769074, dtype: object\n",
      "\n",
      "\n",
      "industry                            retail\n",
      "pred        Commercial Services & Supplies\n",
      "Name: 4767413, dtype: object\n",
      "\n",
      "\n",
      "industry         consumer services\n",
      "pred        Consumer Discretionary\n",
      "Name: 127665, dtype: object\n",
      "\n",
      "\n",
      "industry    wine and spirits\n",
      "pred        Consumer Staples\n",
      "Name: 3427313, dtype: object\n",
      "\n",
      "\n",
      "industry      food beverages\n",
      "pred        Consumer Staples\n",
      "Name: 4202031, dtype: object\n",
      "\n",
      "\n",
      "industry    information technology and services\n",
      "pred                     Information Technology\n",
      "Name: 4314532, dtype: object\n",
      "\n",
      "\n",
      "industry                  internet\n",
      "pred        Information Technology\n",
      "Name: 4998583, dtype: object\n",
      "\n",
      "\n",
      "industry                      maritime\n",
      "pred        Transportation & Logistics\n",
      "Name: 2526855, dtype: object\n",
      "\n",
      "\n",
      "industry    mechanical or industrial engineering\n",
      "pred              Commercial Services & Supplies\n",
      "Name: 4446378, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in df_test.sample(n=10).index:\n",
    "    sample = df_test.iloc[i]\n",
    "\n",
    "    # Tokenize text features\n",
    "    tokenized = tokenizer(sample['text'], padding='max_length', truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict label\n",
    "        outputs=model(**tokenized)\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "        # Store prediction\n",
    "        df_test.loc[i, 'pred'] = le_inv[torch.argmax(probabilities, dim=-1).item()]\n",
    "\n",
    "    print(df_test.loc[i, text_cols+['pred']])\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
